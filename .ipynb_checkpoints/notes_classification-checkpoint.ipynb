{
 "metadata": {
  "name": "",
  "signature": "sha256:2a5bdd0fb93e14cc5e0395a7c740ad9096d24a77dbf104ee613944a6f7d9adc3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#<span style=\"background-color:#66FF99\">Classification<span/>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Most popular classifiers:\n",
      "\n",
      "1. Logistic Regression\n",
      "* Linear Discriminant Analysis\n",
      "* K-nearest neighbors\n",
      "* Trees\n",
      "* Random forests\n",
      "* Boosting\n",
      "* Support Vector machines"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Overview of classification\n",
      "* Classifying a qualitative outcome based on probability\n",
      "* Why not use linear regression? If only 2 possibility, linear regression might be possible using dummy variable approach. \n",
      "* If more than 2 levels, it's preferable to use classification method\n",
      "\n",
      "#<span style=\"background-color:#66FF99\">Logistic Regression<span/>\n",
      "* Models the probability that Y belongs to a particular category\n",
      "\n",
      "$Pr(default = Yes \\mid balance)$ : probability of default given balance, range between 0 and 1\n",
      "\n",
      "* How to model the relationship $p(X) = Pr(Y = 1 \\mid X)$?\n",
      "* Logistic Function:\n",
      "## $p(X) = \\frac {e^{\\beta_0+\\beta_1X}} {1+e^{\\beta_0 + \\beta_1X}}$\n",
      "\n",
      "* To fit the model, we use maximum likelihood\n",
      "\n",
      "## $log(\\frac {p(X)}{1-p(X)}) = \\beta_0 + \\beta_1X$\n",
      "\n",
      "* Left-hand side is called the log-odds or logit. Logistic regression has a logit that is linear in X\n",
      "\n",
      "###Estimating the Regression Coefficients\n",
      "* Use maximum likelihood to fit the model\n",
      "* Intuition: We find coefficients such that the model will yield close to 1 for all individuals who defaulted\n",
      "* $\\beta_1$ = 0.5 : meaning 1 unit increase in $X_1$ will increase the log odds of Y by 0.5\n",
      "* $\\beta_0$ is usually not of interest in logistic regression\n",
      "* Uses z-statistic instead of t-statistics - the larger it is, the null hypothesis is not true, significance evidence of relationship\n",
      "\n",
      "###Multiple Logistic Regression\n",
      "\n",
      "## $log(\\frac {p(X)}{1-p(X)}) = \\beta_0 + \\beta_1X + ... \\beta_pX_p$\n",
      "\n",
      "* Not a popular technique if there are multiple classes due to confounding\n",
      "* Use other methods like LDA which is popular fo multiple-class classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#<span style=\"background-color:#66FF99\">Linear Discriminant Analysis<span/>\n",
      "* Why need another method?\n",
      "    * Parameter estimates for logistic regression are unstable when classes are well-separated\n",
      "    * If n is small, distribution of predictors X is normal in each class\n",
      "    * Sometimes we have more than 2 response classes\n",
      "* Model the distribution of predictors X separately in each response classes and use Bayes' theorem to get $Pr(Y = k \\mid X =x)$\n",
      "* Distributions assumed to be normal\n",
      "* Linear discriminant analysis (LDA) appoximates the Bayes classifier by estimating:\n",
      "    1. $\\pi_k$ (prior probability an observation belongs to kth class)\n",
      "    * $\\mu_k$(mean parameter)\n",
      "    * $\\sigma^2$(variance parameter)\n",
      "* Then compute the decision boundary which is the midpoint between the sample means\n",
      "* 2 types of error: incorrectly assign yes when no (false positive), and no when yes (true positive)\n",
      "* Confusion matrix: to compare predicted vs true status\n",
      "* Change the threshold to reduce the error rate\n",
      "* Overall performance of a classifier is given by the area under the ROC curve\n",
      " * ROC curve displays False Positive against True Positive"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#<span style=\"background-color:#66FF99\">Comparison of Classification Methods<span/>\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Logistic Regression - estimate $\\beta_0$ and $\\beta_1$ : estimated using maximum likehood\n",
      "* LDA = estimate $c_0$ and $c_1$ (functions of mean and variance parameters) : estimated using mean and variance from a normal distribution \n",
      "* Both produce linear decision boundaries\n",
      "* Logistic regression outperform LDA if Gaussian assumptions are not met\n",
      "* KNN is non-parametric, so no assumption about the shape\n",
      "* No 1 method dominate in every situation - all depends on the data!"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}