{
 "metadata": {
  "name": "",
  "signature": "sha256:0e3a062d1daabf52fc4c3ffea880af37032ccffda8942b8af754bf98a950cb9d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#High Dimensional Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Taxonomy\n",
      "- Univariate\n",
      "- Bivariate\n",
      "- Trivariate\n",
      "- Multivariate (high dimensional)\n",
      "\n",
      "###Dimension Reduction\n",
      "- Project the high-D data onto a lower-D subspace using linear or non-linear transformation\n",
      "- Most common: Linear transformation\n",
      "- Lower dimensions embedding\n",
      "- Main method: PCA\n",
      "- Minimize the sum of residual variance\n",
      "\n",
      "###PCA\n",
      "- Singular Value Decomposition (SVD)\n",
      "- X = UDV$^T$\n",
      "- n X k = (n X q)(q X q)(q X k)\n",
      "- choosing q which is smaller than k\n",
      "- how many PC vectors\n",
      "    - enough PC to cover 80-90% of the variance\n",
      "    - Plot a screeplot\n",
      "\n",
      "###Dimensionality Reduction\n",
      "- Linear Methods\n",
      "    - PCA\n",
      "    - SVD\n",
      "    - Multidimensional Scaling\n",
      "- Nonlinear methods\n",
      "    - IsoMap\n",
      "    - Locally Linear Embeddings"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}