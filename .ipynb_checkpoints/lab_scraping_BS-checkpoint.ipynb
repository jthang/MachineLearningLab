{
 "metadata": {
  "name": "",
  "signature": "sha256:a98ba94d3ecc5808e5385d66dc8baeb77072293b1bacd53abb72dc8c8e9074d6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "# import pattern.web as web\n",
      "from bs4 import BeautifulSoup\n",
      "import requests\n",
      "\n",
      "pd.set_option('display.width', 500)\n",
      "pd.set_option('display.max_columns', 100)\n",
      "pd.set_option('display.mpl_style', 'default')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 90
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#BeautifulSoup Documentation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "html_doc = \"\"\"\n",
      "<html><head><title>The Dormouse's story</title></head>\n",
      "<body>\n",
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
      "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
      "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "\n",
      "<p class=\"story\">...</p>\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "soup = BeautifulSoup(html_doc)\n",
      "print(soup.prettify())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<html>\n",
        " <head>\n",
        "  <title>\n",
        "   The Dormouse's story\n",
        "  </title>\n",
        " </head>\n",
        " <body>\n",
        "  <p class=\"title\">\n",
        "   <b>\n",
        "    The Dormouse's story\n",
        "   </b>\n",
        "  </p>\n",
        "  <p class=\"story\">\n",
        "   Once upon a time there were three little sisters; and their names were\n",
        "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
        "    Elsie\n",
        "   </a>\n",
        "   ,\n",
        "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
        "    Lacie\n",
        "   </a>\n",
        "   and\n",
        "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
        "    Tillie\n",
        "   </a>\n",
        "   ;\n",
        "and they lived at the bottom of a well.\n",
        "  </p>\n",
        "  <p class=\"story\">\n",
        "   ...\n",
        "  </p>\n",
        " </body>\n",
        "</html>\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print soup.title\n",
      "print soup.title.name\n",
      "print soup.title.string\n",
      "print soup.title.parent.name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<title>The Dormouse's story</title>\n",
        "title\n",
        "The Dormouse's story\n",
        "head\n"
       ]
      }
     ],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print soup.p\n",
      "print soup.p['class']\n",
      "print soup.a\n",
      "print soup.find_all('a')\n",
      "print soup.find(id='link3')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
        "['title']\n",
        "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
        "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
        "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for link in soup.find_all('a'):\n",
      "    print(link.get('href'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "http://example.com/elsie\n",
        "http://example.com/lacie\n",
        "http://example.com/tillie\n"
       ]
      }
     ],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(soup.get_text())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The Dormouse's story\n",
        "\n",
        "The Dormouse's story\n",
        "Once upon a time there were three little sisters; and their names were\n",
        "Elsie,\n",
        "Lacie and\n",
        "Tillie;\n",
        "and they lived at the bottom of a well.\n",
        "...\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print soup.head\n",
      "print soup.title"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<head><title>The Dormouse's story</title></head>\n",
        "<title>The Dormouse's story</title>\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print soup.body.b\n",
      "print soup.find_all('a')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<b>The Dormouse's story</b>\n",
        "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "head_tag = soup.head\n",
      "print soup.head\n",
      "print soup.head.contents[0]\n",
      "print head_tag.contents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<head><title>The Dormouse's story</title></head>\n",
        "<title>The Dormouse's story</title>\n",
        "[<title>The Dormouse's story</title>]\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title_tag = soup.title\n",
      "print soup.title\n",
      "print soup.title.contents\n",
      "print soup.title.contents[0]\n",
      "print title_tag.contents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<title>The Dormouse's story</title>\n",
        "[u\"The Dormouse's story\"]\n",
        "The Dormouse's story\n",
        "[u\"The Dormouse's story\"]\n"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print soup.title.contents[0]\n",
      "print soup.title.contents[0].string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The Dormouse's story\n",
        "The Dormouse's story\n"
       ]
      }
     ],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for string in soup.stripped_strings:\n",
      "    print(repr(string))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "u\"The Dormouse's story\"\n",
        "u\"The Dormouse's story\"\n",
        "u'Once upon a time there were three little sisters; and their names were'\n",
        "u'Elsie'\n",
        "u','\n",
        "u'Lacie'\n",
        "u'and'\n",
        "u'Tillie'\n",
        "u';\\nand they lived at the bottom of a well.'\n",
        "u'...'\n"
       ]
      }
     ],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "title_tag = soup.title\n",
      "print title_tag.contents[0]\n",
      "print title_tag.parent"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The Dormouse's story\n",
        "<head><title>The Dormouse's story</title></head>\n"
       ]
      }
     ],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sibling_soup = BeautifulSoup(\"<a><b>text1</b><c>text2</c></b></a>\")\n",
      "print(sibling_soup.prettify())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<html>\n",
        " <body>\n",
        "  <a>\n",
        "   <b>\n",
        "    text1\n",
        "   </b>\n",
        "   <c>\n",
        "    text2\n",
        "   </c>\n",
        "  </a>\n",
        " </body>\n",
        "</html>\n"
       ]
      }
     ],
     "prompt_number": 145
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print sibling_soup.b.next_sibling\n",
      "print sibling_soup.c.previous_sibling"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<c>text2</c>\n",
        "<b>text1</b>\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Searching the Tree - find() and find_all()\n",
      "Filtering using\n",
      "* tag's name\n",
      "* attributes\n",
      "* text of a string\n",
      "* combination of all above"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "html_doc = \"\"\"\n",
      "<html><head><title>The Dormouse's story</title></head>\n",
      "<body>\n",
      "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
      "\n",
      "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
      "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
      "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
      "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
      "and they lived at the bottom of a well.</p>\n",
      "\n",
      "<p class=\"story\">...</p>\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 150
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print soup.find_all('b')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[<b>The Dormouse's story</b>]\n"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#find tags that start with b with regex\n",
      "import re\n",
      "for tag in soup.find_all(re.compile(\"^b\")):\n",
      "    print(tag.name)\n",
      "#find tags that start with t with regex\n",
      "for tag in soup.find_all(re.compile(\"t\")):\n",
      "    print(tag.name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "body\n",
        "b\n",
        "html\n",
        "title\n"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#find all that match ANY item in the list\n",
      "soup.find_all([\"a\", \"title\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 157,
       "text": [
        "[<title>The Dormouse's story</title>,\n",
        " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
        " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
        " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
       ]
      }
     ],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#find all the tags\n",
      "for tag in soup.find_all(True):\n",
      "    print(tag.name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "html\n",
        "head\n",
        "title\n",
        "body\n",
        "p\n",
        "b\n",
        "p\n",
        "a\n",
        "a\n",
        "a\n",
        "p\n"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Using a function to filter\n",
      "def has_class_but_no_id(tag):\n",
      "    return tag.has_attr('class') and tag.has_attr('id')\n",
      "\n",
      "soup.find_all(has_class_but_no_id)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 165,
       "text": [
        "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
        " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
        " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print soup.find_all('title')\n",
      "print soup.find_all('p', 'title')\n",
      "print soup.find_all(id='link2')\n",
      "print soup.find_all(id=True)\n",
      "print soup.find_all(href=re.compile(\"elsie\"))\n",
      "print soup.find_all(href=re.compile(\"elsie\"), id='link1')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[<title>The Dormouse's story</title>]\n",
        "[<p class=\"title\"><b>The Dormouse's story</b></p>]\n",
        "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n",
        "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
        "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n",
        "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>]\n"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print soup.find_all(\"a\", class_=\"sister\")\n",
      "print soup.find_all(text=\"Elsie\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
        "[u'Elsie']\n"
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first_link = soup.a\n",
      "first_link.find_all_next('a')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 190,
       "text": [
        "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
        " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#CSS selectors\n",
      "print soup.select('title')\n",
      "print soup.select('body a')\n",
      "print soup.select('p > a')\n",
      "\n",
      "#select by CSS class\n",
      "print soup.select(\".sister\")\n",
      "#select by CSS ID\n",
      "print soup.select(\"#link2\")\n",
      "print soup.select('a[href]')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[<title>The Dormouse's story</title>]\n",
        "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
        "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
        "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
        "[<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n"
       ]
      }
     ],
     "prompt_number": 198
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Reddit"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Example links on the site\n",
      "-------------------------\n",
      "http://www.reddit.com/r/pics/comments/2p1tr8/my_dads_a_trash_truck_driver_he_got_this_today/\n",
      "http://www.reddit.com/r/AskReddit/comments/2p28u1/serious_people_who_went_missing_what_happened/\n",
      "\"\"\"    \n",
      "\n",
      "import requests\n",
      "from pattern import web\n",
      "from fnmatch import fnmatch\n",
      "\n",
      "def is_comments_page(l):\n",
      "    \"\"\"Returns true if link is comments page\"\"\"\n",
      "    pattern = 'http://www.reddit.com/r/*/comments/*/*/'\n",
      "    return fnmatch(l, pattern)\n",
      "\n",
      "def find_comments_pages(html):\n",
      "    dom = web.Element(html)\n",
      "    links = [a.attributes.get('href', '') for a in dom.by_tag('a')]\n",
      "    links = [l for l in links if is_comments_page(l)] \n",
      "    links = list(set(links))#remove duplicates\n",
      "    return links\n",
      "\n",
      "page = requests.get('http://www.reddit.com/').text.encode('ascii', 'ignore')\n",
      "\n",
      "find_comments_pages(page)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[u'http://www.reddit.com/r/Jokes/comments/2p2xub/i_like_my_coffee_like_i_like_my_men/',\n",
        " u'http://www.reddit.com/r/aww/comments/2p1g0d/i_think_i_was_chosen_at_the_humane_society_today/',\n",
        " u'http://www.reddit.com/r/space/comments/2p2hsk/a_great_photo_of_the_milky_way_and_its_reflection/',\n",
        " u'http://www.reddit.com/r/WritingPrompts/comments/2p2xzf/wp_everyones_talking_about_that_crazy_thing_you/',\n",
        " u'http://www.reddit.com/r/science/comments/2p0a7u/morning_work_start_times_should_be_delayed_to/',\n",
        " u'http://www.reddit.com/r/worldnews/comments/2p13tc/isis_releases_horrifying_sex_slave_pamphlet/',\n",
        " u'http://www.reddit.com/r/food/comments/2p16gz/grilled_cheese_on_12grain_wheat_bread_to_dip_in/',\n",
        " u'http://www.reddit.com/r/Fitness/comments/2p1e77/can_exercise_help_my_depression/',\n",
        " u'http://www.reddit.com/r/Showerthoughts/comments/2p0xf3/every_year_reddit_should_take_that_years_top_12/',\n",
        " u'http://www.reddit.com/r/AskReddit/comments/2p2y1t/reddit_what_is_your_favorite_vine_or_short/',\n",
        " u'http://www.reddit.com/r/LifeProTips/comments/2p1cqm/lpt_think_very_carefully_before_establishing/',\n",
        " u'http://www.reddit.com/r/IAmA/comments/2p0yez/warren_g_regulators_mount_up/',\n",
        " u'http://www.reddit.com/r/funny/comments/2p20yq/how_i_returned_my_sisters_computer_after_fixing_it/',\n",
        " u'http://www.reddit.com/r/gaming/comments/2p13x3/piece_of_heart_heart_container_jewels_fan_art/',\n",
        " u'http://www.reddit.com/r/videos/comments/2p1yet/laser_mounted_to_dogs_collar_hilarity_ensues_103/',\n",
        " u'http://www.reddit.com/r/Futurology/comments/2p2pio/this_week_in_technology_an_advanced_laser_defense/',\n",
        " u'http://www.reddit.com/r/mildlyinteresting/comments/2p0nax/this_toothbrush_has_no_bristles/',\n",
        " u'http://www.reddit.com/r/history/comments/2ozuwe/a_crew_is_at_work_in_boston_unearthing_a_time/',\n",
        " u'http://www.reddit.com/r/todayilearned/comments/2p1ux2/til_jon_heder_was_only_paid_1000_for_his_role_as/',\n",
        " u'http://www.reddit.com/r/funny/comments/2p2y2s/mrw_trying_to_find_the_clit/',\n",
        " u'http://www.reddit.com/r/explainlikeimfive/comments/2p2km9/eli5_why_is_there_15_250mbs_internet_in_romania/',\n",
        " u'http://www.reddit.com/r/Jokes/comments/2p20v8/newfie_logic/',\n",
        " u'http://www.reddit.com/r/movies/comments/2p0ub2/star_wars_the_force_awakens_character_names/',\n",
        " u'http://www.reddit.com/r/news/comments/2p2xv4/studentsex_charges_dismissed_against_exassistant/',\n",
        " u'http://www.reddit.com/r/OldSchoolCool/comments/2p2y49/beautiful_courtney_cox_in_1988_photo_by_karen/',\n",
        " u'http://www.reddit.com/r/gifs/comments/2p2o77/stephen_colbert_interviews_smaug/',\n",
        " u'http://www.reddit.com/r/UpliftingNews/comments/2p2h2i/australian_police_arrest_man_just_25_minutes/',\n",
        " u'http://www.reddit.com/r/AskReddit/comments/2p28u1/serious_people_who_went_missing_what_happened/',\n",
        " u'http://www.reddit.com/r/pics/comments/2p1tr8/my_dads_a_trash_truck_driver_he_got_this_today/',\n",
        " u'http://www.reddit.com/r/InternetIsBeautiful/comments/2p2gfe/a_minimalist_beautiful_and_fun_soundbox_patapap/',\n",
        " u'http://www.reddit.com/r/food/comments/2p2xlk/im_chris_nuttallsmith_toronto_restaurant_critic/',\n",
        " u'http://www.reddit.com/r/news/comments/2p1fmq/nasa_gets_2_boost_to_science_budget/',\n",
        " u'http://www.reddit.com/r/Jokes/comments/2p2xvc/yo_momma_joke/',\n",
        " u'http://www.reddit.com/r/Showerthoughts/comments/2p2xi0/if_all_my_fantasies_and_wishes_came_true_the/',\n",
        " u'http://www.reddit.com/r/todayilearned/comments/2p2xxx/til_billy_bob_thornton_has_a_phobia_of_antique/']"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_links_from_front_pages(n):\n",
      "    'find  URLs of comments pages, linked from the n first few pages of reddit'\n",
      "    url = web.URL('http://www.reddit.com/')\n",
      "    comment_pages = []\n",
      "    for page_idx in range(n):\n",
      "        dom = web.DOM(url.download(cached=False))\n",
      "    \n",
      "        for entry in dom('a.comments'):\n",
      "            href = entry.attributes.get('href', '')\n",
      "            if href:\n",
      "                comment_pages.append(href)\n",
      "                \n",
      "        # find the next page link - reddit has 25 links per page\n",
      "        for a in dom('a'):\n",
      "            if ('count=%d' % ((page_idx + 1) * 25)) in a.attributes.get('href', ''):\n",
      "                url = web.URL(a.attributes.get('href'))\n",
      "    # use set() to remove repeated pages\n",
      "    return list(set(comment_pages))\n",
      "\n",
      "            \n",
      "print len(get_links_from_front_pages(6))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "172\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def info_from_comments_pages(links):\n",
      "    'fetch title, upvotes, downvotes, time of submission from a sequence of links'\n",
      "    results = []\n",
      "    for urltext in links:\n",
      "        url = web.URL(urltext)\n",
      "        print \"fetching info for\", url\n",
      "        try:\n",
      "            dom = web.DOM(url.download(cached=False))\n",
      "            title = dom('title')[0].content\n",
      "            upvotes = int(dom.by_class('upvotes')[0].children[0].content.replace(',', ''))\n",
      "            downvotes = int(dom.by_class('downvotes')[0].children[0].content.replace(',', ''))\n",
      "            time = dom.by_class('tagline')[0]('time')[0].attributes.get('datetime')\n",
      "            results.append((title, upvotes, downvotes, pd.to_datetime(time)))\n",
      "        except KeyboardInterrupt:\n",
      "            # allow us to interrupt the kernel but use what we've already fetched\n",
      "            break\n",
      "        except:\n",
      "            pass  # some things that look like comment pages don't have the information above\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    }
   ],
   "metadata": {}
  }
 ]
}